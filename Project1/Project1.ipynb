{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Used for loading and handling data\n",
    "import numpy as np # math functions\n",
    "from collections import Counter \n",
    "\n",
    "# Splitting data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Comparing to existing implementation\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.1 & 1.2 Implementing a decision tree learning algorithm from scratch\n",
    "\n",
    "Below is the implemtation of task 1.1 and 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    def __init__(self, score=None, feature=None, threshold=None, left=None, right=None, \n",
    "                 prediction =None, pred_count = None):\n",
    "        self.score = score\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.prediction = prediction\n",
    "        self.pred_count = pred_count\n",
    "    \n",
    "    # For printing\n",
    "    def __repr__(self):\n",
    "        if self.prediction != None:\n",
    "            return \"PRED: \"+str(self.prediction)+\", count: \"+str(self.pred_count)\n",
    "        else:\n",
    "            return (\"N(\"+str(self.feature)+\",\"+str(self.threshold)+\")\")\n",
    "    \n",
    "    # Comparing to other nodes\n",
    "    def __eq__(self, other):\n",
    "\n",
    "        if other == None:\n",
    "            return False\n",
    "        \n",
    "        if other.left == None:\n",
    "            return self.prediction == other.prediction and self.pred_count == other.pred_count\n",
    "\n",
    "        else:\n",
    "            return self.feature == (other.feature and self.threshold == other.threshold \n",
    "                                   and self.left.__eq__(other.left) and self.right.__eq__(other.right))\n",
    "    \n",
    "    # Flatten a 3 node tree to a single node\n",
    "    def convert_to_pred(self, prediction, pred_count):\n",
    "        self.score = None\n",
    "        self.feature = None\n",
    "        self.threshold = None\n",
    "        self.left = None\n",
    "        self.right = None\n",
    "        self.prediction = prediction\n",
    "        self.pred_count = pred_count\n",
    "\n",
    "class DecisionTree():\n",
    "    \n",
    "    def __init__(self, max_depth):\n",
    "        self.max_depth = max_depth\n",
    "        self.root = None\n",
    "        self.X_n = None\n",
    "    \n",
    "    def set_root(self, n):\n",
    "        self.root = n\n",
    "    \n",
    "    def impurity(self, y, impurity_measure):\n",
    "        _, class_counts = np.unique(y, return_counts=True)\n",
    "        probs = class_counts / np.sum(class_counts)\n",
    "\n",
    "        if impurity_measure == \"entropy\":\n",
    "            impurity = -1 * np.sum(np.log2(probs) * probs)\n",
    "        if impurity_measure == \"gini\":\n",
    "            impurity = 1-np.sum(probs**2)\n",
    "\n",
    "        return impurity\n",
    "\n",
    "    \n",
    "    # Finding optimal split of dataset based on impurity measure\n",
    "    def opt_split(self, X, y, impurity_measure):\n",
    "        m, n = X.shape\n",
    "\n",
    "        c_score = self.impurity(y, impurity_measure)\n",
    "        c_feature = None\n",
    "        c_threshold = None\n",
    "        X_left = None\n",
    "        X_right = None\n",
    "        y_left = None\n",
    "        y_right =None\n",
    "\n",
    "        for f in range(n):\n",
    "            \n",
    "            # One could use both mean and median to find split in dataset\n",
    "            f_mean = np.mean(X[:,f])\n",
    "            #f_median = np.median(X[:,f])\n",
    "\n",
    "            left = np.where(X[:,f] < f_mean)\n",
    "            right = np.where(X[:,f] >= f_mean)\n",
    "            \n",
    "            left_score = self.impurity(y[left], impurity_measure)\n",
    "            right_score = self.impurity(y[right], impurity_measure)\n",
    "\n",
    "            wheighted_score = (len(left[0])*left_score + (len(right[0])*right_score)) / (len(left[0]) + len(right[0]))\n",
    "\n",
    "            if wheighted_score < c_score:\n",
    "                c_score = wheighted_score\n",
    "                c_feature = f\n",
    "                c_threshold = f_mean\n",
    "                X_left = X[left]\n",
    "                X_right = X[right]\n",
    "                y_left = y[left]\n",
    "                y_right = y[right]\n",
    "                \n",
    "\n",
    "        return c_score, c_feature, c_threshold, X_left, X_right, y_left, y_right\n",
    "    \n",
    "    \n",
    "    # Recursive function to fit a tree \n",
    "    def fit(self, X, y, impurity_measure, c_depth = 0):\n",
    "\n",
    "        if c_depth == 0:\n",
    "            m, n = X.shape\n",
    "            self.X_n = n\n",
    "\n",
    "        if c_depth == self.max_depth:\n",
    "            p = Counter(y).most_common(1)[0]\n",
    "            return Node(prediction=p[0], pred_count=p[1])\n",
    "\n",
    "        if np.all(y == y[0]):\n",
    "            p = Counter(y).most_common(1)[0]\n",
    "            return Node(prediction=p[0], pred_count=p[1])\n",
    "\n",
    "        if np.all(np.all(X == X[0,:], axis = 0)):\n",
    "            p = Counter(y).most_common(1)[0]\n",
    "            return Node(prediction=p[0], pred_count=p[1])\n",
    "\n",
    "        else:\n",
    "            (c_score, c_feature, c_threshold, X_left, X_right, y_left, y_right) = self.opt_split(X, y, impurity_measure)\n",
    "            \n",
    "            return Node(score = c_score,\n",
    "                        feature = c_feature,\n",
    "                        threshold = c_threshold,\n",
    "                        left = self.fit(X_left, y_left, c_depth = c_depth+1, impurity_measure = impurity_measure),\n",
    "                        right = self.fit(X_right, y_right, c_depth = c_depth+1, impurity_measure = impurity_measure)\n",
    "                       )\n",
    "    \n",
    "    # Predicting on data using fitted tree \n",
    "    def predict(self, x, node=None):\n",
    "        if node == None:\n",
    "            if self.X_n != len(x):\n",
    "                raise ValueError(\"Prediction input must be the same size as training data\")\n",
    "            node = self.root\n",
    "\n",
    "        if node.right == None or node.left == None:\n",
    "            return node.prediction\n",
    "        if x[node.feature] < node.threshold:\n",
    "            return self.predict(x, node.left)\n",
    "        else:\n",
    "            return self.predict(x, node.right)\n",
    "\n",
    "# Recursive function to visualize tree in terminal\n",
    "def print_tree(root, space = 0) :\n",
    "    if (root == None) :\n",
    "        return\n",
    "\n",
    "    space += 4\n",
    "    print_tree(root.right, space)\n",
    "    for i in range(4, space):\n",
    "        print(end = \" \")\n",
    "    print(root)\n",
    "    print_tree(root.left, space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learn(X, y, impurity_measure= \"entropy\", max_depth = 5, prune = False):\n",
    "    tree = DecisionTree(max_depth)\n",
    "    if prune == True:\n",
    "        \n",
    "        # Pruning data\n",
    "        X_t, X_prune, Y_t, Y_prune = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "        root = tree.fit(X_t,Y_t, impurity_measure)\n",
    "        tree.set_root(root)\n",
    "\n",
    "        root_acc = accuracy_score(Y_prune,[tree.predict(x) for x in X_prune])\n",
    "\n",
    "        # Prune function prunes all leaves. To prune entire tree it runs maximum depth-1\n",
    "        pruned_root = prune_f(tree, root_acc, max_depth, X_prune, Y_prune)\n",
    "        tree.set_root(pruned_root)\n",
    "        \n",
    "        for i in range(1,max_depth-1): # Cannot prune more than depth:\n",
    "            pruned_root_i = prune_f(tree, root_acc, max_depth, X_prune, Y_prune)\n",
    "\n",
    "            # Break if there there is not any more pruning changes\n",
    "            if pruned_root_i == tree.root: \n",
    "                break\n",
    "\n",
    "            tree.set_root(pruned_root_i)\n",
    "\n",
    "        return tree\n",
    "    else:\n",
    "        root = tree.fit(X,y, impurity_measure)\n",
    "        tree.set_root(root)\n",
    "        return tree\n",
    "\n",
    "def predict(x, tree):\n",
    "    return tree.predict(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.3 - Add reduced-error pruning\n",
    "\n",
    "Helping function for pruning trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_f(tree, root_acc, depth, X_prune, Y_prune, node = None):\n",
    "\n",
    "    #Base cases\n",
    "    if node == None:\n",
    "        node = tree.root\n",
    "    if node.prediction != None:\n",
    "        return node\n",
    "        \n",
    "    if (node.left.prediction != None) and (node.right.prediction != None):\n",
    "        # If two leaves have identical label, combine\n",
    "        if(node.left.prediction == node.right.prediction):\n",
    "            return Node(prediction=node.left.prediction, pred_count = (node.left.pred_count+node.right.pred_count))\n",
    "            \n",
    "        else:\n",
    "            # Replacing with majority label\n",
    "            save_score, save_feature, save_threshold = node.score, node.feature, node.threshold\n",
    "            l = node.left\n",
    "            r = node.right\n",
    "\n",
    "            left_majority = (l.pred_count > r.pred_count)\n",
    "            \n",
    "            node.left = None\n",
    "            node.right = None\n",
    "\n",
    "            if (left_majority):\n",
    "                node.convert_to_pred(l.prediction, l.pred_count)\n",
    "            else:\n",
    "                node.convert_to_pred(r.prediction, r.pred_count)\n",
    "\n",
    "\n",
    "            prune_acc = accuracy_score(Y_prune,[tree.predict(x) for x in X_prune])\n",
    "\n",
    "            # Replacing node if accuracy is higher\n",
    "            if (prune_acc > root_acc):\n",
    "                if left_majority:\n",
    "                    return Node(prediction=l.prediction,pred_count=l.pred_count)\n",
    "                else:\n",
    "                    return Node(prediction=r.prediction,pred_count=r.pred_count)\n",
    "            # Else we keep the old\n",
    "            else:\n",
    "                return Node(save_score, save_feature, save_threshold, left = l, right = r)\n",
    "\n",
    "    # Recursive call\n",
    "    else:\n",
    "        return Node(node.score, node.feature,node.threshold,\n",
    "                    left = prune_f(tree, root_acc, depth, X_prune, Y_prune, node = node.left),\n",
    "                    right = prune_f(tree, root_acc, depth, X_prune, Y_prune, node = node.right)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.4 - Evaluate your algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X0</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28.7967</td>\n",
       "      <td>16.0021</td>\n",
       "      <td>2.6449</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>0.1982</td>\n",
       "      <td>27.7004</td>\n",
       "      <td>22.0110</td>\n",
       "      <td>-8.2027</td>\n",
       "      <td>40.0920</td>\n",
       "      <td>81.8828</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.6036</td>\n",
       "      <td>11.7235</td>\n",
       "      <td>2.5185</td>\n",
       "      <td>0.5303</td>\n",
       "      <td>0.3773</td>\n",
       "      <td>26.2722</td>\n",
       "      <td>23.8238</td>\n",
       "      <td>-9.9574</td>\n",
       "      <td>6.3609</td>\n",
       "      <td>205.2610</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>162.0520</td>\n",
       "      <td>136.0310</td>\n",
       "      <td>4.0612</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>116.7410</td>\n",
       "      <td>-64.8580</td>\n",
       "      <td>-45.2160</td>\n",
       "      <td>76.9600</td>\n",
       "      <td>256.7880</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.8172</td>\n",
       "      <td>9.5728</td>\n",
       "      <td>2.3385</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.3922</td>\n",
       "      <td>27.2107</td>\n",
       "      <td>-6.4633</td>\n",
       "      <td>-7.1513</td>\n",
       "      <td>10.4490</td>\n",
       "      <td>116.7370</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>75.1362</td>\n",
       "      <td>30.9205</td>\n",
       "      <td>3.1611</td>\n",
       "      <td>0.3168</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>-5.5277</td>\n",
       "      <td>28.5525</td>\n",
       "      <td>21.8393</td>\n",
       "      <td>4.6480</td>\n",
       "      <td>356.4620</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         X0        X1      X2      X3      X4        X5       X6       X7  \\\n",
       "0   28.7967   16.0021  2.6449  0.3918  0.1982   27.7004  22.0110  -8.2027   \n",
       "1   31.6036   11.7235  2.5185  0.5303  0.3773   26.2722  23.8238  -9.9574   \n",
       "2  162.0520  136.0310  4.0612  0.0374  0.0187  116.7410 -64.8580 -45.2160   \n",
       "3   23.8172    9.5728  2.3385  0.6147  0.3922   27.2107  -6.4633  -7.1513   \n",
       "4   75.1362   30.9205  3.1611  0.3168  0.1832   -5.5277  28.5525  21.8393   \n",
       "\n",
       "        X8        X9  Y  \n",
       "0  40.0920   81.8828  g  \n",
       "1   6.3609  205.2610  g  \n",
       "2  76.9600  256.7880  g  \n",
       "3  10.4490  116.7370  g  \n",
       "4   4.6480  356.4620  g  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading data\n",
    "data = pd.read_csv(\"magic04.data\", header=None)\n",
    "data.columns = [\"X\"+str(i) for i in range(0,10)] + [\"Y\"]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting\n",
    "X = data.drop([\"Y\"], axis = 1)\n",
    "Y = data[\"Y\"]\n",
    "\n",
    "X_train, X_val_test, Y_train, Y_val_test = train_test_split(X, Y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_test, Y_val_test, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descicion tree with max depth: 2, impurity measure: entropy, prune: True, Accuracy: 75.18%\n",
      "Descicion tree with max depth: 2, impurity measure: entropy, prune: False, Accuracy: 75.18%\n",
      "Descicion tree with max depth: 2, impurity measure: gini, prune: True, Accuracy: 75.18%\n",
      "Descicion tree with max depth: 2, impurity measure: gini, prune: False, Accuracy: 75.18%\n",
      "Descicion tree with max depth: 3, impurity measure: entropy, prune: True, Accuracy: 78.97%\n",
      "Descicion tree with max depth: 3, impurity measure: entropy, prune: False, Accuracy: 78.90%\n",
      "Descicion tree with max depth: 3, impurity measure: gini, prune: True, Accuracy: 78.97%\n",
      "Descicion tree with max depth: 3, impurity measure: gini, prune: False, Accuracy: 78.90%\n",
      "Descicion tree with max depth: 4, impurity measure: entropy, prune: True, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 4, impurity measure: entropy, prune: False, Accuracy: 80.72%\n",
      "Descicion tree with max depth: 4, impurity measure: gini, prune: True, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 4, impurity measure: gini, prune: False, Accuracy: 80.72%\n",
      "Descicion tree with max depth: 5, impurity measure: entropy, prune: True, Accuracy: 82.23%\n",
      "Descicion tree with max depth: 5, impurity measure: entropy, prune: False, Accuracy: 82.19%\n",
      "Descicion tree with max depth: 5, impurity measure: gini, prune: True, Accuracy: 82.23%\n",
      "Descicion tree with max depth: 5, impurity measure: gini, prune: False, Accuracy: 82.19%\n",
      "Descicion tree with max depth: 6, impurity measure: entropy, prune: True, Accuracy: 83.46%\n",
      "Descicion tree with max depth: 6, impurity measure: entropy, prune: False, Accuracy: 82.97%\n",
      "Descicion tree with max depth: 6, impurity measure: gini, prune: True, Accuracy: 83.46%\n",
      "Descicion tree with max depth: 6, impurity measure: gini, prune: False, Accuracy: 83.18%\n",
      "Descicion tree with max depth: 7, impurity measure: entropy, prune: True, Accuracy: 83.67%\n",
      "Descicion tree with max depth: 7, impurity measure: entropy, prune: False, Accuracy: 83.46%\n",
      "Descicion tree with max depth: 7, impurity measure: gini, prune: True, Accuracy: 83.81%\n",
      "Descicion tree with max depth: 7, impurity measure: gini, prune: False, Accuracy: 83.63%\n",
      "Descicion tree with max depth: 8, impurity measure: entropy, prune: True, Accuracy: 84.33%\n",
      "Descicion tree with max depth: 8, impurity measure: entropy, prune: False, Accuracy: 84.19%\n",
      "Descicion tree with max depth: 8, impurity measure: gini, prune: True, Accuracy: 84.26%\n",
      "Descicion tree with max depth: 8, impurity measure: gini, prune: False, Accuracy: 84.51%\n",
      "Descicion tree with max depth: 9, impurity measure: entropy, prune: True, Accuracy: 83.14%\n",
      "Descicion tree with max depth: 9, impurity measure: entropy, prune: False, Accuracy: 83.98%\n",
      "Descicion tree with max depth: 9, impurity measure: gini, prune: True, Accuracy: 83.60%\n",
      "Descicion tree with max depth: 9, impurity measure: gini, prune: False, Accuracy: 84.40%\n",
      "Descicion tree with max depth: 10, impurity measure: entropy, prune: True, Accuracy: 83.46%\n",
      "Descicion tree with max depth: 10, impurity measure: entropy, prune: False, Accuracy: 82.90%\n",
      "Descicion tree with max depth: 10, impurity measure: gini, prune: True, Accuracy: 84.16%\n",
      "Descicion tree with max depth: 10, impurity measure: gini, prune: False, Accuracy: 83.04%\n",
      "Descicion tree with max depth: 11, impurity measure: entropy, prune: True, Accuracy: 83.25%\n",
      "Descicion tree with max depth: 11, impurity measure: entropy, prune: False, Accuracy: 81.81%\n",
      "Descicion tree with max depth: 11, impurity measure: gini, prune: True, Accuracy: 83.25%\n",
      "Descicion tree with max depth: 11, impurity measure: gini, prune: False, Accuracy: 82.09%\n",
      "Descicion tree with max depth: 12, impurity measure: entropy, prune: True, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 12, impurity measure: entropy, prune: False, Accuracy: 81.18%\n",
      "Descicion tree with max depth: 12, impurity measure: gini, prune: True, Accuracy: 80.69%\n",
      "Descicion tree with max depth: 12, impurity measure: gini, prune: False, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 13, impurity measure: entropy, prune: True, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 13, impurity measure: entropy, prune: False, Accuracy: 80.55%\n",
      "Descicion tree with max depth: 13, impurity measure: gini, prune: True, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 13, impurity measure: gini, prune: False, Accuracy: 80.16%\n",
      "Descicion tree with max depth: 14, impurity measure: entropy, prune: True, Accuracy: 80.83%\n",
      "Descicion tree with max depth: 14, impurity measure: entropy, prune: False, Accuracy: 80.20%\n",
      "Descicion tree with max depth: 14, impurity measure: gini, prune: True, Accuracy: 81.53%\n",
      "Descicion tree with max depth: 14, impurity measure: gini, prune: False, Accuracy: 79.50%\n"
     ]
    }
   ],
   "source": [
    "#depth = list(range(2, 15))\n",
    "depth = list(range(2,15)) # For grading you should probably run less samples to save time\n",
    "impurity_measure = [\"entropy\", \"gini\"]\n",
    "prune = [True, False]\n",
    "\n",
    "df_l = []\n",
    "\n",
    "# Checking accuracy for all combinatios of settings on validation data\n",
    "for d in depth:\n",
    "    for i in impurity_measure:\n",
    "        for p in prune:\n",
    "            clf = learn(X_train.to_numpy(),Y_train.to_numpy(), max_depth = d, impurity_measure=i, prune=p)\n",
    "            val_pred = [predict(x, clf) for x in X_val.to_numpy()]\n",
    "            acc = accuracy_score(Y_val, val_pred)*100\n",
    "            df_l.append([d,i,p,acc])\n",
    "            print(\"Descicion tree with max depth: \"+str(d) + \", impurity measure: \"+i+\", prune:\",str(p)+\n",
    "                  \", Accuracy: {:3.2f}%\".format(acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will comment this out for grading in case grader dont have plotly installed\n",
    "\n",
    "#import plotly.express as px #For visualization\n",
    "\n",
    "#Plotting data\n",
    "#df = pd.DataFrame(df_l, columns = ['Depth', 'Impurity', 'Prune', 'Accuracy'])\n",
    "#px.line(df, x=\"Depth\", y = 'Accuracy', color='Impurity', symbol='Prune', title=\"Model accuracy on validation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Accuracy](acc.png)\n",
    "\n",
    "**Which setting should you select for this data (entropy or\n",
    "gini, pruning or no pruning)?** \n",
    "- The settings produce fairly similar perfomance, though the gini impurity measures slightly outperforms entropy.\n",
    "- We also see that pruning decreases accuracy for depth <10, but increases for larger depths\n",
    "- We select gini index with depth of 8 based on validation data.\n",
    "\n",
    "**What is your estimate for the performance the selected model on unseen data points? Report how you arrived at the\n",
    "conclusions.**\n",
    "- We estimate based on the visualization that the model will predict correctly in around 85& of cases on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTree Test accuracy: 85.21%\n"
     ]
    }
   ],
   "source": [
    "# Test accuracy using best parameters as stated above\n",
    "\n",
    "clf = learn(X_train.to_numpy(),Y_train.to_numpy(), max_depth = 9, impurity_measure=\"gini\", prune=False)\n",
    "clf_Y_test_pred = [predict(x, clf) for x in X_test.to_numpy()]\n",
    "clf_acc = accuracy_score(Y_test, clf_Y_test_pred)*100\n",
    "print(\"DecisionTree Test accuracy: {:3.2f}%\".format(clf_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our estimation is confirmed by test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1.5 - Compare to an existing implementation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_leaf': [1, 2],\n",
       "                         'min_samples_split': [2, 3, 4]},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_param = {\n",
    "    'criterion':['gini','entropy'],\n",
    "    'max_depth':[3,4,5,6,7,8,9,10],\n",
    "    'min_samples_split': [2,3,4],\n",
    "    'min_samples_leaf': [1,2]\n",
    "    }\n",
    "sklearn_clf = GridSearchCV(DecisionTreeClassifier(random_state=42), tree_param, cv=5, verbose=1)\n",
    "sklearn_clf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![sklearn tree](tree.png)\n",
    "\n",
    "Visualization of the tree produced by sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn DecisionTreeClassifier best params: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_leaf': 1, 'min_samples_split': 2}\n",
      "sklearn DecisionTreeClassifier test accuracy: 85.63%\n",
      "Versus implementation form scratch test accuracy: 85.21%\n"
     ]
    }
   ],
   "source": [
    "print(\"sklearn DecisionTreeClassifier best params: \" + str(sklearn_clf.best_params_))\n",
    "sklearn_clf_Y_test_pred = sklearn_clf.predict(X_test)\n",
    "print(\"sklearn DecisionTreeClassifier test accuracy: {:3.2f}%\".format(accuracy_score(Y_test, sklearn_clf_Y_test_pred)*100))\n",
    "print(\"Versus implementation form scratch test accuracy: {:3.2f}%\".format(clf_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does your implementation fare against this implementation in terms of\n",
    "accuracy and speed? Can you explain the (possible) differences?**\n",
    "- Our implementation is strikingly similar in performance and optimal settings. As we saw in the graph above there was not a significant difference between gini and entropy, and the optimal depth range was 8-9.\n",
    "- The accuracy is similar: 85,63% VS 85,21%\n",
    "- The speed is also similar for fitting\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef5acb2d32b7338650a24161520397f3c0f9f5a78ae59cdb4e82088468d38fef"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
